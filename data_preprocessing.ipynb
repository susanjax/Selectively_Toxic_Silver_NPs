{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "N-I52t45MiAm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "HZbkpYJEXpy0"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = pd.read_csv('/content/ko_matrix_merged_3056rows.csv')"
      ],
      "metadata": {
        "id": "0GeRWibMXsyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49436ab6-5076-4178-c206-1fe396895cea"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4018363993.py:1: DtypeWarning: Columns (9,18,20,21,24,44,45,46,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_small = pd.read_csv('/content/ko_matrix_merged_3056rows.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_medium = pd.read_csv('/content/path_matrix_merged_3056rows.csv')"
      ],
      "metadata": {
        "id": "PpwY0Ms0moQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_big = pd.read_csv('/content/gene_matrix_merged_3056rows_105249cols.csv')"
      ],
      "metadata": {
        "id": "CD7Lnkr9XvYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_columns(df):\n",
        "  mic_vals = ['MIC', 'MBC', 'MBEC', 'MBIC', 'MIc', 'MFC', 'MMC']\n",
        "  mic = df[df['method'].isin(mic_vals)]\n",
        "  zoi = df[df['method'] == 'ZOI']\n",
        "\n",
        "  # check percentage of missing vals in columns(Concentration of precursor (mM))\n",
        "  missing = mic['Concentration of precursor (mM)'].isna().sum().item()\n",
        "  if missing / mic.shape[0] > 0.5:\n",
        "    mic.drop(columns = ['Concentration of precursor (mM)'], inplace = True)\n",
        "  missing = zoi['Concentration of precursor (mM)'].isna().sum().item()\n",
        "  if missing / zoi.shape[0] > 0.5:\n",
        "    zoi.drop(columns = ['Concentration of precursor (mM)'], inplace = True)\n",
        "\n",
        "  # check missing for hydrodynamic diameter\n",
        "  missing = mic['hydrodynamic diameter'].isna().sum().item()\n",
        "  if missing / mic.shape[0] > 0.5:\n",
        "    mic.drop(columns = ['hydrodynamic diameter'], inplace = True)\n",
        "  missing = zoi['hydrodynamic diameter'].isna().sum().item()\n",
        "  if missing / zoi.shape[0] > 0.5:\n",
        "    zoi.drop(columns = ['hydrodynamic diameter'], inplace = True)\n",
        "\n",
        "  # check missing for ph During\n",
        "  missing = mic['pH during synthesis'].isna().sum().item()\n",
        "  if missing / mic.shape[0] > 0.5:\n",
        "    mic.drop(columns = ['pH during synthesis'], inplace = True)\n",
        "  missing = zoi['pH during synthesis'].isna().sum().item()\n",
        "  if missing / zoi.shape[0] > 0.5:\n",
        "    zoi.drop(columns = ['pH during synthesis'], inplace = True)\n",
        "\n",
        "  mic.drop(columns = ['np'], inplace = True)\n",
        "  mic.drop(columns = ['concentration for ZOI (µg/ml)'])\n",
        "  zoi.drop(columns = ['np'], inplace = True)\n",
        "\n",
        "  return mic, zoi"
      ],
      "metadata": {
        "id": "C54OU_fnlOT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mic_clear, zoi_clear = drop_columns(df_small)"
      ],
      "metadata": {
        "id": "7jduOLTGqKAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess mic and zoi**"
      ],
      "metadata": {
        "id": "65V94M_2r_pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mic_clear.isna().sum()[mic_clear.isna().sum() > 0]"
      ],
      "metadata": {
        "id": "o6sW2dM0ry4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_dataset(mic_clear):\n",
        "  mic_clear.drop(columns = ['strain'], inplace = True)\n",
        "  # input avg, if min and max missed\n",
        "  mask_avg = mic_clear['np_size_avg (nm)'].notna()\n",
        "  mic_clear.loc[mask_avg & mic_clear['np_size_min (nm)'].isna(), 'np_size_min (nm)'] = mic_clear.loc[mask_avg, 'np_size_avg (nm)']\n",
        "  mic_clear.loc[mask_avg & mic_clear['np_size_max (nm)'].isna(), 'np_size_max (nm)'] = mic_clear.loc[mask_avg, 'np_size_avg (nm)']\n",
        "\n",
        "# if min, max, calc avg\n",
        "  mask_minmax = mic_clear['np_size_min (nm)'].notna() & mic_clear['np_size_max (nm)'].notna()\n",
        "  mic_clear.loc[mask_minmax & mic_clear['np_size_avg (nm)'].isna(), 'np_size_avg (nm)'] = (\n",
        "    mic_clear.loc[mask_minmax, 'np_size_min (nm)'] + mic_clear.loc[mask_minmax, 'np_size_max (nm)']\n",
        "  ) / 2\n",
        "\n",
        "# drop vals where all are missing\n",
        "  mask_all_na = mic_clear[['np_size_min (nm)', 'np_size_max (nm)', 'np_size_avg (nm)']].isna().all(axis=1)\n",
        "  mic_clear = mic_clear[~mask_all_na]\n",
        "\n",
        "  mic_clear['shape'].fillna(value = mic_clear['shape'].mode()[0], inplace = True)\n",
        "  mic_clear['time_set (hours)'].fillna(value = mic_clear['time_set (hours)'].mean(), inplace = True)\n",
        "  mic_clear.drop(columns = ['zeta_potential (mV)'], inplace = True)\n",
        "  mic_clear['Solvent for extract'].fillna(value = mic_clear['Solvent for extract'].mode()[0], inplace = True)\n",
        "  mic_clear['Temperature for extract, C'].fillna(value = mic_clear['Temperature for extract, C'].mode()[0], inplace = True)\n",
        "  mic_clear['Precursor of NP'].fillna(value = mic_clear['Precursor of NP'].mode()[0], inplace = True)\n",
        "  mic_clear['Duration preparing extract, min'].fillna(value = mic_clear['Duration preparing extract, min'].mean(), inplace = True)\n",
        "  # mic_clear['Concentration of precursor (mM)'].fillna(value = mic_clear['Concentration of precursor (mM)'].mean(), inplace = True)\n",
        "  mic_clear.drop(columns = ['Strain', 'Unnamed: 44', 'Clade', 'accept/reject', 'comment', 'accept/reject', 'entry_status',\n",
        "                          'has_mistake_in_matadata', 'has_mistake_in_data', 'verification_date', 'verified_by'], inplace = True)\n",
        "  mic_clear.dropna(subset=['bac_type'], inplace = True)\n",
        "\n",
        "  return mic_clear"
      ],
      "metadata": {
        "id": "EzwK_qFZ-XA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mic_clear = clear_dataset(mic_clear)"
      ],
      "metadata": {
        "id": "6Ibd992gsjUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "zoi_clear = clear_dataset(zoi_clear)"
      ],
      "metadata": {
        "id": "dKCjQz0cHYxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mic_med, zoi_med = drop_columns(df_small)"
      ],
      "metadata": {
        "id": "I9pZXjxv_NRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mic_med = clear_dataset(mic_med)"
      ],
      "metadata": {
        "id": "Rs6YIXul_qLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mic_big, zoi_big = drop_columns(df_big)"
      ],
      "metadata": {
        "id": "THn_04YL_wXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mic_big = clear_dataset(mic_big)"
      ],
      "metadata": {
        "id": "lJ4I8l7K_5Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "zoi_big = clear_dataset(zoi_big)"
      ],
      "metadata": {
        "id": "2uAkRArvHp2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_subsets(df, target = 'MIC'):\n",
        "  target_cols = {'MIC':'MIC_NP (µg/mL)', 'ZOI': 'zoi_np (mm)'}\n",
        "  if target == 'MIC':\n",
        "    X = df.drop(columns = [target_cols[target], 'concentration for ZOI (µg/ml)',\n",
        "                           'reference', 'doi', 'article_list', 'journal_name',\n",
        "                           'publisher', 'year', 'title', 'journal_is_oa', 'is_oa',\n",
        "                           'oa_status', 'verification required','verified_by', 'verification_date',\n",
        "                           'has_mistake_in_data','has_mistake_in_matadata', 'entry_status', 'comment',\n",
        "                           'accept/reject', 'Unnamed: 44'])\n",
        "    y = df[target_cols[target]]\n",
        "    x_train, y_train, x_val, y_val = train_test_split(X, y)\n",
        "  else:\n",
        "    X = df.drop(columns = [target_cols[target], 'reference', 'doi', 'article_list', 'journal_name',\n",
        "                           'publisher', 'year', 'title', 'journal_is_oa', 'is_oa',\n",
        "                           'oa_status', 'verification required','verified_by', 'verification_date',\n",
        "                           'has_mistake_in_data','has_mistake_in_matadata', 'entry_status', 'comment',\n",
        "                           'accept/reject', 'Unnamed: 44'])\n",
        "    y = df[target_cols[target]]\n",
        "    x_train, y_train, x_val, y_val = train_test_split(X, y)\n",
        "  return x_train, y_train, x_val, y_val"
      ],
      "metadata": {
        "id": "qw1oQO4XAsnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_train_feat(df):\n",
        "    model_cat = CatBoostRegressor(iterations=100, verbose=False, random_state=42)\n",
        "    model_lin = LinearRegression()\n",
        "\n",
        "    x_train, x_val, y_train, y_val = create_subsets(df)\n",
        "\n",
        "    cat_features = [\n",
        "        'np', 'bacteria', 'strain', 'np_synthesis', 'method', 'shape',\n",
        "        'Solvent for extract', 'Precursor of NP', 'Bacteria', 'Strain',\n",
        "        'Superkingdom', 'Kingdom', 'Clade', 'Phylum', 'Class', 'Order',\n",
        "        'Family', 'Genus', 'Species', 'bac_type'\n",
        "    ]\n",
        "\n",
        "    cat_features_exist = [f for f in cat_features if f in x_train.columns]\n",
        "\n",
        "    train_pool = Pool(data=x_train, label=y_train, cat_features=cat_features_exist)\n",
        "\n",
        "    print('Data prepared. Training models...')\n",
        "\n",
        "    model_cat.fit(train_pool)\n",
        "    y_pred_cat = model_cat.predict(x_val)\n",
        "    metrics_cat = {\n",
        "        'mae': mean_absolute_error(y_val, y_pred_cat),\n",
        "        'mse': mean_squared_error(y_val, y_pred_cat),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_val, y_pred_cat)),\n",
        "        'r2': r2_score(y_val, y_pred_cat)\n",
        "    }\n",
        "\n",
        "    x_train_lin = x_train.drop(columns=cat_features_exist)\n",
        "    x_val_lin = x_val.drop(columns=cat_features_exist)\n",
        "    model_lin.fit(x_train_lin, y_train)\n",
        "    y_pred_lin = model_lin.predict(x_val_lin)\n",
        "    metrics_lin = {\n",
        "        'mae': mean_absolute_error(y_val, y_pred_lin),\n",
        "        'mse': mean_squared_error(y_val, y_pred_lin),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_val, y_pred_lin)),\n",
        "        'r2': r2_score(y_val, y_pred_lin)\n",
        "    }\n",
        "\n",
        "    print('Calculating and saving feature importances...')\n",
        "    X = pd.concat([x_train, x_val])\n",
        "\n",
        "    shap_cat = shap.TreeExplainer(model_cat)\n",
        "    shap_values_cat = shap_cat(X)\n",
        "    shap.plots.beeswarm(shap_values_cat, show=False)\n",
        "    plt.savefig(\"beeswarm_plot_cat.png\", bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    importance = model_cat.get_feature_importance()\n",
        "    features = model_cat.feature_names_\n",
        "    plt.barh(features, importance)\n",
        "    plt.title(\"Feature Importance (CatBoost)\")\n",
        "    plt.savefig(\"feature_importance.png\", bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    X_lin = X.drop(columns=cat_features_exist)\n",
        "    explainer_lin = shap.LinearExplainer(model_lin, X_lin)\n",
        "    shap_values_lin = explainer_lin(X_lin)\n",
        "    shap.plots.beeswarm(shap_values_lin, show=False)\n",
        "    plt.savefig(\"beeswarm_plot_lin.png\", bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    print('Done.')\n",
        "    return {'catboost': metrics_cat, 'linear_regression': metrics_lin}"
      ],
      "metadata": {
        "id": "h8hCxkKVAFNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_train_feat(zoi_clear)"
      ],
      "metadata": {
        "id": "zli8CTDFOHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOxnsE2IOLMu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}